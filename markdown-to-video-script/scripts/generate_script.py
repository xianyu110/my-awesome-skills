#!/usr/bin/env python3
"""
ç”Ÿæˆå£æ’­ç¨¿å’Œè§†é¢‘è„šæœ¬ V3
çŸ­è§†é¢‘é£æ ¼ï¼šèŠ‚å¥å¿«ã€å£è¯­åŒ–ã€æœ‰ç…½åŠ¨æ€§
"""
import re
import json
import sys
from pathlib import Path
from typing import List, Dict


def extract_images(markdown_content: str) -> List[Dict[str, str]]:
    """æå– Markdown ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    pattern = r'!\[(.*?)\]\((.*?)\)'
    matches = re.findall(pattern, markdown_content)
    
    images = []
    for idx, (alt_text, url) in enumerate(matches, 1):
        images.append({
            'id': idx,
            'url': url,
            'alt': alt_text,
            'description': alt_text or f'é…å›¾ {idx}'
        })
    
    return images


def clean_text(text: str) -> str:
    """æ¸…ç† Markdown æ ‡è®°"""
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    text = re.sub(r'```[\s\S]*?```', '', text)
    text = re.sub(r'#+\s+', '', text)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'[_`]', '', text)
    text = re.sub(r'\n\s*\n+', '\n\n', text)
    text = re.sub(r'^---+$', '', text, flags=re.MULTILINE)
    return text


def generate_narration_v3(markdown_content: str, target_words: int = 400) -> str:
    """
    ç”Ÿæˆå£æ’­ç¨¿ V3 - çŸ­è§†é¢‘é£æ ¼
    å‚è€ƒï¼šèŠ‚å¥å¿«ã€å£è¯­åŒ–ã€æœ‰ç…½åŠ¨æ€§
    """
    text = clean_text(markdown_content)
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip() and len(p.strip()) > 5]
    
    # æå–æ ¸å¿ƒå†…å®¹
    opening_lines = []
    tech_lines = []
    reason_lines = []
    
    for p in paragraphs:
        # å¼€åœºç—›ç‚¹
        if any(kw in p for kw in ['ä½ æœ‰æ²¡æœ‰', 'æƒ³è±¡', 'é‡åˆ°']) and len(opening_lines) < 2:
            opening_lines.append(p)
        
        # æŠ€å·§å†…å®¹
        if any(kw in p for kw in ['ä¸éœ€è¦', 'åªéœ€', 'æ“ä½œ', 'ç®€å•', 'ç²˜è´´', 'è¾“å…¥', 'ç‚¹å‡»']) and len(p) < 100:
            tech_lines.append(p)
        
        # åŸå› /ä¼˜åŠ¿
        if any(kw in p for kw in ['åŸç”Ÿ', 'æ”¯æŒ', 'Token', 'ä¸Šä¸‹æ–‡', 'å…è´¹', 'å›½å†…']) and len(p) < 100:
            reason_lines.append(p)
    
    # ç»„è£…å£æ’­ç¨¿ï¼ˆçŸ­è§†é¢‘é£æ ¼ï¼‰
    parts = []
    
    # 1. å¼€å¤´å¼•å¯¼
    parts.append("å¦‚éœ€ç½‘å€ï¼Œå…³æ³¨åæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
    
    # 2. çƒ­ç‚¹å¼•å…¥
    parts.append("ä»Šå¤©ç»™å¤§å®¶åˆ†äº«ä¸¤ä¸ªæŠ€å·§ï¼Œç”¨Geminiçœ‹YouTubeï¼Œæ•ˆç‡ç›´æ¥æå‡10å€ï¼")
    
    # 3. ç—›ç‚¹å…±é¸£ï¼ˆ1-2å¥ï¼‰
    if opening_lines:
        parts.extend(opening_lines[:2])
    else:
        parts.append("YouTubeä¸Šçœ‹åˆ°å¥½è§†é¢‘ï¼Œ2å°æ—¶é•¿ï¼Œå…¨è‹±æ–‡ï¼Œæ²¡å­—å¹•ï¼Œæƒ³çœ‹ä½†æ²¡æ—¶é—´ï¼Œç›´æ¥æ”¾å¼ƒã€‚")
    
    # 4. æŠ€å·§1
    parts.append("ç¬¬ä¸€ä¸ªæŠ€å·§ï¼šä¸€é”®æå–å®Œæ•´å­—å¹•ã€‚")
    if tech_lines:
        parts.append(tech_lines[0])
    else:
        parts.append("ä¸éœ€è¦ä¸‹è½½ï¼Œä¸éœ€è¦æ’ä»¶ã€‚æ‰“å¼€Geminiï¼Œç²˜è´´YouTubeé“¾æ¥ï¼Œè¾“å…¥æç¤ºè¯ï¼Œå®Œæ•´å­—å¹•å°±å‡ºæ¥äº†ã€‚")
    
    # 5. æŠ€å·§2
    parts.append("ç¬¬äºŒä¸ªæŠ€å·§ï¼šä¸ªæ€§åŒ–è¾“å‡ºæ ¸å¿ƒå†…å®¹ã€‚")
    parts.append("é¢å¯¹2å°æ—¶é•¿è§†é¢‘ï¼Œç”¨ä¸€æ®µæç¤ºè¯ï¼Œè®©Geminiåƒè¯¾ä»£è¡¨ä¸€æ ·å¸®ä½ åˆ’é‡ç‚¹ã€‚è¾“å‡ºç›®å½•ã€æ‘˜è¦ã€å…³é”®è¦ç‚¹ï¼Œä¸€ç›®äº†ç„¶ã€‚")
    
    # 6. ä¸ºä»€ä¹ˆé€‰æ‹©
    parts.append("ä¸ºä»€ä¹ˆé€‰Geminiï¼Ÿä¸‰ä¸ªåŸå› ï¼š")
    parts.append("åŸç”Ÿæ”¯æŒè§†é¢‘åˆ†æï¼Œä¸ç”¨ä¸‹è½½è½¬å½•ï¼›100ä¸‡Tokenä¸Šä¸‹æ–‡ï¼Œå¤„ç†è¶…é•¿è§†é¢‘ï¼›å›½å†…å…è´¹å¯ç”¨ï¼Œæ— éœ€é­”æ³•ã€‚")
    
    # 7. è¡ŒåŠ¨å·å¬
    parts.append("è¯ä¸å¤šè¯´ï¼Œæƒ³è¦ç”¨è¿™ä¸ªå…è´¹AIå·¥å…·çš„å°ä¼™ä¼´ï¼Œè§†é¢‘ä¸‹æ–¹ä¸€é”®ä¸‰è¿ï¼Œè¯„è®ºåŒºè§ï¼")
    
    narration = '\n\n'.join(parts)
    
    # ç»Ÿè®¡å­—æ•°
    word_count = len(narration.replace('\n', '').replace(' ', ''))
    
    # å¦‚æœè¶…å‡ºï¼Œè¿›ä¸€æ­¥å‹ç¼©
    if word_count > target_words * 1.3:
        compressed = []
        compressed.append("å¦‚éœ€ç½‘å€ï¼Œå…³æ³¨åæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
        compressed.append("ä»Šå¤©åˆ†äº«ä¸¤ä¸ªæŠ€å·§ï¼Œç”¨Geminiçœ‹YouTubeï¼Œæ•ˆç‡æå‡10å€ï¼")
        compressed.append("YouTubeå¥½è§†é¢‘ï¼Œ2å°æ—¶é•¿ï¼Œå…¨è‹±æ–‡ï¼Œæ²¡å­—å¹•ï¼Œæƒ³çœ‹æ²¡æ—¶é—´ã€‚")
        compressed.append("ç¬¬ä¸€ä¸ªæŠ€å·§ï¼šä¸€é”®æå–å­—å¹•ã€‚æ‰“å¼€Geminiï¼Œç²˜è´´é“¾æ¥ï¼Œè¾“å…¥æç¤ºè¯ï¼Œå­—å¹•å°±å‡ºæ¥äº†ã€‚")
        compressed.append("ç¬¬äºŒä¸ªæŠ€å·§ï¼šä¸ªæ€§åŒ–è¾“å‡ºã€‚ç”¨æç¤ºè¯è®©Geminiåˆ’é‡ç‚¹ï¼Œè¾“å‡ºç›®å½•å’Œæ‘˜è¦ã€‚")
        compressed.append("ä¸ºä»€ä¹ˆé€‰Geminiï¼ŸåŸç”Ÿæ”¯æŒè§†é¢‘ã€100ä¸‡Tokenä¸Šä¸‹æ–‡ã€å›½å†…å…è´¹ã€‚")
        compressed.append("æƒ³è¦ç”¨çš„å°ä¼™ä¼´ï¼Œä¸€é”®ä¸‰è¿ï¼Œè¯„è®ºåŒºè§ï¼")
        narration = '\n\n'.join(compressed)
    
    return narration


def generate_timeline(narration: str, images: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆè§†é¢‘æ—¶é—´è½´"""
    paragraphs = [p.strip() for p in narration.split('\n\n') if p.strip()]
    
    timeline = []
    current_time = 0
    
    for idx, paragraph in enumerate(paragraphs):
        # ä¼°ç®—åœç•™æ—¶é•¿ï¼ˆçŸ­è§†é¢‘èŠ‚å¥æ›´å¿«ï¼Œæ¯ä¸ªå­—çº¦ 0.25 ç§’ï¼‰
        char_count = len(paragraph.replace(' ', ''))
        duration = max(2, min(8, char_count * 0.25))
        
        # åŒ¹é…é…å›¾
        image_id = min(idx + 1, len(images)) if images else None
        
        timeline.append({
            'start': round(current_time, 2),
            'end': round(current_time + duration, 2),
            'duration': round(duration, 2),
            'text': paragraph,
            'image_id': image_id
        })
        
        current_time += duration
    
    return timeline


def generate_script(markdown_file: str, output_dir: str = './output') -> Dict:
    """ç”Ÿæˆå®Œæ•´è§†é¢‘è„šæœ¬"""
    with open(markdown_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ ‡é¢˜
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    title = title_match.group(1) if title_match else Path(markdown_file).stem
    
    # ç”Ÿæˆå£æ’­ç¨¿
    narration = generate_narration_v3(content)
    word_count = len(narration.replace('\n', '').replace(' ', ''))
    
    # æå–é…å›¾
    images = extract_images(content)
    
    # ç”Ÿæˆæ—¶é—´è½´
    timeline = generate_timeline(narration, images)
    
    # ç»„è£…è„šæœ¬
    script = {
        'title': title,
        'source_file': markdown_file,
        'narration': narration,
        'word_count': word_count,
        'images': images,
        'timeline': timeline,
        'total_duration': timeline[-1]['end'] if timeline else 0
    }
    
    # ä¿å­˜è„šæœ¬
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    script_file = output_path / 'script.json'
    with open(script_file, 'w', encoding='utf-8') as f:
        json.dump(script, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å£æ’­ç¨¿
    narration_file = output_path / 'narration.txt'
    with open(narration_file, 'w', encoding='utf-8') as f:
        f.write(narration)
    
    print(f"âœ… è„šæœ¬ç”Ÿæˆå®Œæˆ")
    print(f"ğŸ“ å£æ’­ç¨¿ï¼š{word_count} å­—")
    print(f"ğŸ–¼ï¸  é…å›¾æ•°ï¼š{len(images)} å¼ ")
    print(f"â±ï¸  é¢„è®¡æ—¶é•¿ï¼š{script['total_duration']:.1f} ç§’")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_path.absolute()}")
    
    return script


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_script_v3.py <markdown_file> [output_dir]")
        sys.exit(1)
    
    markdown_file = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else './output'
    
    generate_script(markdown_file, output_dir)
