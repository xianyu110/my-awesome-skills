#!/usr/bin/env python3
"""
ç”Ÿæˆå£æ’­ç¨¿å’Œè§†é¢‘è„šæœ¬ V2
åŸºäºç”¨æˆ·çš„å†™ä½œé£æ ¼æ¨¡æ¿
"""
import re
import json
import sys
from pathlib import Path
from typing import List, Dict


def extract_images(markdown_content: str) -> List[Dict[str, str]]:
    """æå– Markdown ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    pattern = r'!\[(.*?)\]\((.*?)\)'
    matches = re.findall(pattern, markdown_content)
    
    images = []
    for idx, (alt_text, url) in enumerate(matches, 1):
        images.append({
            'id': idx,
            'url': url,
            'alt': alt_text,
            'description': alt_text or f'é…å›¾ {idx}'
        })
    
    return images


def clean_text(text: str) -> str:
    """æ¸…ç† Markdown æ ‡è®°"""
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    text = re.sub(r'```[\s\S]*?```', '', text)
    text = re.sub(r'#+\s+', '', text)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'[_`]', '', text)
    text = re.sub(r'\n\s*\n+', '\n\n', text)
    text = re.sub(r'^---+$', '', text, flags=re.MULTILINE)
    return text


def generate_narration_v2(markdown_content: str, target_words: int = 500) -> str:
    """
    ç”Ÿæˆå£æ’­ç¨¿ V2
    ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·çš„é£æ ¼æ¨¡æ¿ï¼š
    1. å¼€åœºç™½ï¼ˆå¼•å…¥é—®é¢˜ï¼‰
    2. æŠ€å·§1ï¼ˆç®€æ´è¯´æ˜ï¼‰
    3. æŠ€å·§2ï¼ˆç®€æ´è¯´æ˜ï¼‰
    4. ä¸ºä»€ä¹ˆé€‰æ‹©ï¼ˆ3ä¸ªåŸå› ï¼‰
    5. ä½¿ç”¨å»ºè®®
    6. æ€»ç»“ + è¡ŒåŠ¨å·å¬
    """
    text = clean_text(markdown_content)
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip() and len(p.strip()) > 5]
    
    # æå–å„éƒ¨åˆ†å†…å®¹
    opening = []
    tech1_content = []
    tech2_content = []
    reasons = []
    suggestions = []
    closing = []
    
    in_tech1 = False
    in_tech2 = False
    in_reasons = False
    in_suggestions = False
    
    for p in paragraphs:
        # å¼€åœºç™½
        if any(kw in p for kw in ['ä½ æœ‰æ²¡æœ‰', 'æƒ³è±¡ä¸€ä¸‹', 'å¤§å®¶å¥½', 'ä»Šå¤©åˆ†äº«']) and not opening:
            opening.append(p)
        elif len(opening) > 0 and len(opening) < 4 and not in_tech1:
            opening.append(p)
        
        # æŠ€å·§1
        if 'æŠ€å·§1' in p or 'ä¸€é”®æå–' in p:
            in_tech1 = True
            in_tech2 = False
        elif in_tech1 and ('æŠ€å·§2' in p or 'ä¸ªæ€§åŒ–è¾“å‡º' in p):
            in_tech1 = False
            in_tech2 = True
        elif in_tech1 and len(tech1_content) < 4:
            if len(p) < 150 and ('ä¸éœ€è¦' in p or 'åªéœ€' in p or 'æ“ä½œ' in p or 'æ•ˆæœ' in p or 'å®æµ‹' in p):
                tech1_content.append(p)
        
        # æŠ€å·§2
        elif in_tech2 and len(tech2_content) < 4:
            if len(p) < 150 and ('é¢å¯¹' in p or 'å¸Œæœ›' in p or 'è¾“å‡º' in p or 'å¯ä»¥' in p):
                tech2_content.append(p)
        
        # ä¸ºä»€ä¹ˆé€‰æ‹©
        if 'ä¸ºä»€ä¹ˆé€‰Gemini' in p or 'ä¸ºä»€ä¹ˆä¸ç”¨ChatGPT' in p:
            in_reasons = True
            in_tech2 = False
        elif in_reasons and len(reasons) < 4:
            if 'ä¼˜åŠ¿' in p or 'åŸå› ' in p or 'æ”¯æŒ' in p or 'ä¸Šä¸‹æ–‡' in p or 'å…è´¹' in p:
                reasons.append(p)
        
        # ä½¿ç”¨å»ºè®®
        if 'ä½¿ç”¨å»ºè®®' in p or 'æˆ‘çš„å»ºè®®' in p:
            in_suggestions = True
            in_reasons = False
        elif in_suggestions and len(suggestions) < 3:
            if len(p) < 120:
                suggestions.append(p)
        
        # ç»“å°¾
        if any(kw in p for kw in ['æ€»ç»“', 'å¥½äº†', 'ç‚¹èµ', 'è½¬å‘', 'ä¿¡æ¯çˆ†ç‚¸']):
            closing.append(p)
    
    # ç»„è£…å£æ’­ç¨¿ï¼ˆä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿ï¼‰
    narration_parts = []
    
    # 0. å¼€å¤´å¼•å¯¼ï¼ˆå›ºå®šï¼‰
    narration_parts.append("å¦‚éœ€ç½‘å€ï¼Œå…³æ³¨åæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
    
    # 1. å¼€åœºç™½
    if opening:
        narration_parts.append("å¤§å®¶å¥½ï¼ä»Šå¤©åˆ†äº«ä¸¤ä¸ªæˆ‘è—äº†åŠå¹´çš„æŠ€å·§ï¼Œç”¨Geminiçœ‹YouTubeï¼Œæ•ˆç‡ç›´æ¥æå‡10å€ã€‚")
        narration_parts.extend(opening[:3])
    
    # 2. æŠ€å·§1
    narration_parts.append("**ç¬¬ä¸€ä¸ªæŠ€å·§ï¼šä¸€é”®æå–å®Œæ•´å­—å¹•**")
    if tech1_content:
        narration_parts.extend(tech1_content[:3])
    else:
        narration_parts.append("ä¸éœ€è¦ä¸‹è½½è§†é¢‘ï¼Œä¹Ÿä¸éœ€è¦å®‰è£…æ’ä»¶ã€‚æ‰“å¼€Geminiï¼Œç›´æ¥æŠŠYouTubeé“¾æ¥ç²˜è´´è¿›å»ï¼Œè¾“å…¥æç¤ºè¯ï¼Œå°±èƒ½çœ‹åˆ°å®Œæ•´å­—å¹•ã€‚")
    
    # 3. æŠ€å·§2
    narration_parts.append("**ç¬¬äºŒä¸ªæŠ€å·§ï¼šä¸ªæ€§åŒ–è¾“å‡ºæ ¸å¿ƒå†…å®¹**")
    if tech2_content:
        narration_parts.extend(tech2_content[:3])
    else:
        narration_parts.append("é¢å¯¹2å°æ—¶çš„é•¿è§†é¢‘ï¼Œå¯ä»¥ç”¨æ›´å¼ºå¤§çš„æç¤ºè¯ï¼Œè®©Geminiåƒè¯¾ä»£è¡¨ä¸€æ ·å¸®ä½ åˆ’é‡ç‚¹ã€‚")
    
    # 4. ä¸ºä»€ä¹ˆé€‰Gemini
    narration_parts.append("**ä¸ºä»€ä¹ˆé€‰Geminiï¼Ÿ**")
    if reasons:
        # æå–3ä¸ªåŸå› 
        reason_texts = []
        for r in reasons:
            if 'åŸç”Ÿæ”¯æŒ' in r or 'è§†é¢‘åˆ†æ' in r:
                reason_texts.append("ç¬¬ä¸€ï¼ŒåŸç”Ÿæ”¯æŒè§†é¢‘åˆ†æï¼Œä¸ç”¨ä¸‹è½½è½¬å½•")
            elif 'Token' in r or 'ä¸Šä¸‹æ–‡' in r or 'è¶…é•¿' in r:
                reason_texts.append("ç¬¬äºŒï¼Œ100ä¸‡Tokenä¸Šä¸‹æ–‡ï¼Œå¯ä»¥å¤„ç†è¶…é•¿è§†é¢‘")
            elif 'å…è´¹' in r or 'å›½å†…' in r or 'é­”æ³•' in r:
                reason_texts.append("ç¬¬ä¸‰ï¼Œå›½å†…å…è´¹å¯ç”¨ï¼Œæ— éœ€é­”æ³•")
        
        if reason_texts:
            narration_parts.append("ï¼›".join(reason_texts[:3]) + "ã€‚")
        else:
            narration_parts.append("ä¸‰ä¸ªåŸå› ï¼šåŸç”Ÿæ”¯æŒè§†é¢‘åˆ†æã€100ä¸‡Tokenä¸Šä¸‹æ–‡ã€å›½å†…å…è´¹å¯ç”¨ã€‚")
    else:
        narration_parts.append("ä¸‰ä¸ªåŸå› ï¼šåŸç”Ÿæ”¯æŒè§†é¢‘åˆ†æã€100ä¸‡Tokenä¸Šä¸‹æ–‡ã€å›½å†…å…è´¹å¯ç”¨ã€‚")
    
    # 5. ä½¿ç”¨å»ºè®®ï¼ˆå¯é€‰ï¼‰
    if suggestions:
        narration_parts.append("**æˆ‘çš„ä½¿ç”¨å»ºè®®**")
        narration_parts.extend(suggestions[:2])
    
    # 6. æ€»ç»“
    if closing:
        # åªæ·»åŠ æ€»ç»“éƒ¨åˆ†ï¼Œä¸åŒ…å«"ç‚¹èµè½¬å‘"
        summary = [c for c in closing if 'ç‚¹èµ' not in c and 'è½¬å‘' not in c]
        if summary:
            narration_parts.extend(summary[-1:])
        else:
            narration_parts.append("åœ¨ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ç¼ºçš„ä¸æ˜¯ä¿¡æ¯ï¼Œè€Œæ˜¯æœ‰æ•ˆç­›é€‰å’Œå¸æ”¶ä¿¡æ¯çš„æ–¹æ³•ã€‚å–„ç”¨AIï¼Œå¯ä»¥æŠŠæˆ‘ä»¬ä»ä½æ•ˆçš„ä¿¡æ¯å¤„ç†ä¸­è§£æ”¾å‡ºæ¥ã€‚")
    else:
        narration_parts.append("åœ¨ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ç¼ºçš„ä¸æ˜¯ä¿¡æ¯ï¼Œè€Œæ˜¯æœ‰æ•ˆç­›é€‰å’Œå¸æ”¶ä¿¡æ¯çš„æ–¹æ³•ã€‚å–„ç”¨AIï¼Œå¯ä»¥æŠŠæˆ‘ä»¬ä»ä½æ•ˆçš„ä¿¡æ¯å¤„ç†ä¸­è§£æ”¾å‡ºæ¥ã€‚")
    
    # 7. å¼•å¯¼è¡ŒåŠ¨ï¼ˆå›ºå®šç»“å°¾ï¼Œæ€»æ˜¯æ·»åŠ ï¼‰
    narration_parts.append("å¥½äº†ï¼Œä»Šå¤©çš„åˆ†äº«å°±åˆ°è¿™é‡Œã€‚å¦‚éœ€ç½‘å€ï¼Œä¸‰è¿å…³æ³¨UPï¼ŒæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
    
    # ç»„åˆ
    narration = '\n\n'.join(narration_parts)
    
    # ç»Ÿè®¡å­—æ•°å¹¶è°ƒæ•´
    word_count = len(narration.replace('\n', '').replace(' ', '').replace('*', ''))
    
    # å¦‚æœè¶…å‡ºå¤ªå¤šï¼Œå‹ç¼©
    if word_count > target_words * 1.3:
        compressed = []
        compressed.append("å¦‚éœ€ç½‘å€ï¼Œå…³æ³¨åæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
        compressed.append("å¤§å®¶å¥½ï¼ä»Šå¤©åˆ†äº«ä¸¤ä¸ªæŠ€å·§ï¼Œç”¨Geminiçœ‹YouTubeï¼Œæ•ˆç‡æå‡10å€ã€‚")
        compressed.extend(opening[:2])
        compressed.append("**ç¬¬ä¸€ä¸ªæŠ€å·§ï¼šä¸€é”®æå–å®Œæ•´å­—å¹•**")
        compressed.extend(tech1_content[:2])
        compressed.append("**ç¬¬äºŒä¸ªæŠ€å·§ï¼šä¸ªæ€§åŒ–è¾“å‡ºæ ¸å¿ƒå†…å®¹**")
        compressed.extend(tech2_content[:2])
        compressed.append("**ä¸ºä»€ä¹ˆé€‰Geminiï¼Ÿ**")
        compressed.append("ä¸‰ä¸ªåŸå› ï¼šåŸç”Ÿæ”¯æŒè§†é¢‘åˆ†æã€100ä¸‡Tokenä¸Šä¸‹æ–‡ã€å›½å†…å…è´¹å¯ç”¨ã€‚")
        compressed.extend(closing[-2:])
        compressed.append("å¥½äº†ï¼Œä»Šå¤©çš„åˆ†äº«å°±åˆ°è¿™é‡Œã€‚å¦‚éœ€ç½‘å€ï¼Œä¸‰è¿å…³æ³¨UPï¼ŒæŸ¥çœ‹åå°ç§ä¿¡å³å¯ï¼")
        narration = '\n\n'.join(compressed)
    
    return narration


def generate_timeline(narration: str, images: List[Dict]) -> List[Dict]:
    """ç”Ÿæˆè§†é¢‘æ—¶é—´è½´"""
    paragraphs = [p.strip() for p in narration.split('\n\n') if p.strip()]
    
    timeline = []
    current_time = 0
    
    for idx, paragraph in enumerate(paragraphs):
        # ä¼°ç®—åœç•™æ—¶é•¿ï¼ˆæ¯ä¸ªå­—çº¦ 0.3 ç§’ï¼‰
        char_count = len(paragraph.replace(' ', '').replace('*', ''))
        duration = max(3, min(10, char_count * 0.3))
        
        # åŒ¹é…é…å›¾
        image_id = min(idx + 1, len(images)) if images else None
        
        timeline.append({
            'start': round(current_time, 2),
            'end': round(current_time + duration, 2),
            'duration': round(duration, 2),
            'text': paragraph.replace('**', ''),
            'image_id': image_id
        })
        
        current_time += duration
    
    return timeline


def generate_script(markdown_file: str, output_dir: str = './output') -> Dict:
    """ç”Ÿæˆå®Œæ•´è§†é¢‘è„šæœ¬"""
    with open(markdown_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå–æ ‡é¢˜
    title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    title = title_match.group(1) if title_match else Path(markdown_file).stem
    
    # ç”Ÿæˆå£æ’­ç¨¿
    narration = generate_narration_v2(content)
    word_count = len(narration.replace('\n', '').replace(' ', '').replace('*', ''))
    
    # æå–é…å›¾
    images = extract_images(content)
    
    # ç”Ÿæˆæ—¶é—´è½´
    timeline = generate_timeline(narration, images)
    
    # ç»„è£…è„šæœ¬
    script = {
        'title': title,
        'source_file': markdown_file,
        'narration': narration,
        'word_count': word_count,
        'images': images,
        'timeline': timeline,
        'total_duration': timeline[-1]['end'] if timeline else 0
    }
    
    # ä¿å­˜è„šæœ¬
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    script_file = output_path / 'script.json'
    with open(script_file, 'w', encoding='utf-8') as f:
        json.dump(script, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å£æ’­ç¨¿
    narration_file = output_path / 'narration.txt'
    with open(narration_file, 'w', encoding='utf-8') as f:
        f.write(narration)
    
    print(f"âœ… è„šæœ¬ç”Ÿæˆå®Œæˆ")
    print(f"ğŸ“ å£æ’­ç¨¿ï¼š{word_count} å­—")
    print(f"ğŸ–¼ï¸  é…å›¾æ•°ï¼š{len(images)} å¼ ")
    print(f"â±ï¸  é¢„è®¡æ—¶é•¿ï¼š{script['total_duration']:.1f} ç§’")
    print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{output_path.absolute()}")
    
    return script


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_script_v2.py <markdown_file> [output_dir]")
        sys.exit(1)
    
    markdown_file = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else './output'
    
    generate_script(markdown_file, output_dir)
